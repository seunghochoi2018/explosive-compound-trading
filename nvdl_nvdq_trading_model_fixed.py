#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NVDL/NVDQ ìˆ˜ìµíŒ¨í„´ í•™ìŠµ ëª¨ë¸ (ìˆ˜ì • ë²„ì „)
- ëª¨ë¸ í•™ìŠµ ë¬¸ì œ í•´ê²°
- ì‹ ë¢°ë„ ê³„ì‚° ë¡œì§ ê°œì„ 
- GradientBoosting, LogisticRegression ì´ˆê¸°í™” ë¬¸ì œ ìˆ˜ì •
- NaN ë°ì´í„° ì²˜ë¦¬ ì™„ì „ í•´ê²°

*** ì¤‘ìš”: FMP APIë§Œ ì‚¬ìš©! yfinance ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€! ***
ë°ì´í„° ì†ŒìŠ¤: Financial Modeling Prep API (FMP)
- ì‹¤ì‹œê°„ ë°ì´í„°: FMP Real-time API
- íˆìŠ¤í† ë¦¬ ë°ì´í„°: FMP Historical API
- yfinanceëŠ” ì‹ ë¢°ì„± ë¬¸ì œë¡œ ì‚¬ìš© ê¸ˆì§€
- ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ì€ nvdl_nvdq_data_collector.pyë¥¼ í†µí•´ì„œë§Œ ì§„í–‰
"""

import json
import time
import pickle
import os
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from collections import deque
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë“¤
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# ë°ì´í„° ìˆ˜ì§‘ê¸° ì„í¬íŠ¸
from nvdl_nvdq_data_collector import NVDLNVDQDataCollector

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

class NVDLNVDQTradingModel:
    def __init__(self, fmp_api_key: str):
        """NVDL/NVDQ ê±°ë˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        print("=== NVDL/NVDQ ìˆ˜ìµíŒ¨í„´ í•™ìŠµ ëª¨ë¸ (ìˆ˜ì • ë²„ì „) ===")
        print("ëª¨ë¸ í•™ìŠµ ë¬¸ì œ í•´ê²° ë° ì‹ ë¢°ë„ ê°œì„ ")

        # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        self.data_collector = NVDLNVDQDataCollector(fmp_api_key)

        # ê±°ë˜ ì„¤ì •
        self.symbols = ['NVDL', 'NVDQ']
        self.current_position = None
        self.position_entry_time = None
        self.position_entry_price = None

        # AI ëª¨ë¸ë“¤ (ì•™ìƒë¸”) - ìµœì í™”ëœ ì„¤ì •
        self.models = {
            'rf': RandomForestClassifier(
                n_estimators=50,
                max_depth=8,
                random_state=42,
                n_jobs=-1,
                min_samples_split=5,
                min_samples_leaf=2
            ),
            'gb': GradientBoostingClassifier(
                n_estimators=50,
                max_depth=5,
                random_state=42,
                learning_rate=0.1,
                min_samples_split=5,
                min_samples_leaf=2
            ),
            'lr': LogisticRegression(
                max_iter=1000,
                random_state=42,
                n_jobs=-1,
                solver='lbfgs',
                warm_start=False
            )
        }

        if XGBOOST_AVAILABLE:
            self.models['xgb'] = xgb.XGBClassifier(
                n_estimators=50,
                max_depth=5,
                random_state=42,
                n_jobs=-1,
                learning_rate=0.1
            )

        # ëª¨ë¸ ê°€ì¤‘ì¹˜ (ì„±ëŠ¥ì— ë”°ë¼ ë™ì  ì¡°ì •)
        self.model_weights = {name: 1.0 for name in self.models.keys()}

        # ë°ì´í„° ì „ì²˜ë¦¬
        self.scaler = StandardScaler()
        self.is_fitted = False
        self.last_training_data = None

        # íŒ¨í„´ ë©”ëª¨ë¦¬
        self.success_patterns = deque(maxlen=100000)
        self.recent_trades = deque(maxlen=10000)

        # ì„±ê³¼ ì¶”ì 
        self.total_trades = 0
        self.winning_trades = 0
        self.total_profit = 0.0
        self.win_rate = 0.0

        # ê±°ë˜ ì‹ í˜¸ ì„¤ì • (ë” ë¯¼ê°í•˜ê²Œ)
        self.signal_thresholds = {
            'buy_nvdl': 0.52,    # 52% ì´ìƒì´ë©´ NVDL ë§¤ìˆ˜
            'buy_nvdq': 0.48,    # 48% ì´í•˜ë©´ NVDQ ë§¤ìˆ˜
            'min_confidence': 0.03  # ìµœì†Œ ì‹ ë¢°ë„ ë§¤ìš° ë‚®ì¶¤
        }

        # ìºì‹œ íŒŒì¼
        self.model_file = "nvdl_nvdq_models_fixed.pkl"
        self.patterns_file = "nvdl_nvdq_patterns_fixed.pkl"

        print(f"ëª¨ë¸ êµ¬ì„±: {list(self.models.keys())}")
        print(f"XGBoost ì‚¬ìš©: {XGBOOST_AVAILABLE}")

    def load_historical_patterns(self):
        """ê¸°ì¡´ ì„±ê³µ íŒ¨í„´ë“¤ ë¡œë“œ"""
        try:
            with open(self.patterns_file, 'rb') as f:
                data = pickle.load(f)
                self.success_patterns = data.get('success_patterns', deque(maxlen=100000))
                self.recent_trades = data.get('recent_trades', deque(maxlen=10000))
                print(f"íŒ¨í„´ ë¡œë“œ ì™„ë£Œ: {len(self.success_patterns)}ê°œ")
                return True
        except:
            return False

    def save_patterns(self):
        """íŒ¨í„´ ë°ì´í„° ì €ì¥"""
        try:
            with open(self.patterns_file, 'wb') as f:
                pickle.dump({
                    'success_patterns': self.success_patterns,
                    'recent_trades': self.recent_trades,
                    'saved_at': datetime.now().isoformat()
                }, f)
        except Exception as e:
            print(f"íŒ¨í„´ ì €ì¥ ì˜¤ë¥˜: {e}")

    def load_models(self):
        """í•™ìŠµëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        try:
            with open(self.model_file, 'rb') as f:
                data = pickle.load(f)
                self.models = data.get('models', self.models)
                self.model_weights = data.get('model_weights', self.model_weights)
                self.scaler = data.get('scaler', StandardScaler())
                self.is_fitted = data.get('is_fitted', False)
                self.last_training_data = data.get('last_training_data', None)
                print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. í•™ìŠµ ìƒíƒœ: {self.is_fitted}")
                return True
        except:
            return False

    def save_models(self):
        """í•™ìŠµëœ ëª¨ë¸ë“¤ ì €ì¥"""
        try:
            with open(self.model_file, 'wb') as f:
                pickle.dump({
                    'models': self.models,
                    'model_weights': self.model_weights,
                    'scaler': self.scaler,
                    'is_fitted': self.is_fitted,
                    'last_training_data': self.last_training_data,
                    'saved_at': datetime.now().isoformat()
                }, f)
                print("ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")

    def prepare_training_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„"""
        print("í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        if not self.data_collector.features_data:
            self.data_collector.load_data()
            if not self.data_collector.features_data:
                print("íŠ¹ì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None, None

        X_list = []
        y_list = []

        # ê° ì‹¬ë³¼ì˜ ë°ì´í„°ì—ì„œ í•™ìŠµ ìƒ˜í”Œ ìƒì„±
        for symbol in self.symbols:
            for interval in ['daily', '1hour', '5min']:
                data_key = f"{symbol}_{interval}"
                if data_key in self.data_collector.features_data:
                    df = self.data_collector.features_data[data_key]
                    if df is not None and len(df) > 30:
                        X_samples, y_samples = self._create_samples_from_dataframe(df, symbol)
                        if len(X_samples) > 0:
                            X_list.extend(X_samples)
                            y_list.extend(y_samples)

        # ì„±ê³µ íŒ¨í„´ì—ì„œ ì¶”ê°€ ìƒ˜í”Œ
        for pattern in list(self.success_patterns)[-5000:]:  # ìµœê·¼ 5000ê°œë§Œ
            if 'features' in pattern and 'label' in pattern:
                X_list.append(pattern['features'])
                y_list.append(pattern['label'])

        if not X_list:
            print("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ íŒ¨í„´ ìƒì„±...")
            self._generate_minimal_patterns()
            return self.prepare_training_data()

        X = np.array(X_list)
        y = np.array(y_list)

        print(f"í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ íŠ¹ì„±")
        print(f"ë¼ë²¨ ë¶„í¬: NVDL={np.sum(y == 1)}, NVDQ={np.sum(y == 0)}")

        return X, y

    def _create_samples_from_dataframe(self, df: pd.DataFrame, symbol: str) -> Tuple[List, List]:
        """DataFrameì—ì„œ í•™ìŠµ ìƒ˜í”Œ ìƒì„±"""
        X_samples = []
        y_samples = []

        feature_columns = [
            'close_sma_5_ratio', 'close_sma_10_ratio', 'close_sma_20_ratio',
            'volatility_5_norm', 'volatility_20_norm',
            'momentum_5', 'momentum_10', 'momentum_20',
            'volume_ratio', 'rsi_14', 'bb_position',
            'price_position_10', 'price_position_20',
            'high_low_ratio', 'close_open_ratio'
        ]

        df['future_return'] = df['close'].shift(-5) / df['close'] - 1

        step_size = max(1, len(df) // 2000)
        for i in range(0, len(df) - 5, step_size):
            features = []
            for col in feature_columns:
                if col in df.columns and not pd.isna(df.iloc[i][col]):
                    val = df.iloc[i][col]
                    # NaNê³¼ Inf ê°’ ì¶”ê°€ ì²˜ë¦¬
                    if np.isnan(val) or np.isinf(val):
                        features.append(0.0)
                    else:
                        features.append(float(val))
                else:
                    features.append(0.0)

            if len(features) == 15:
                volatility_trend = df.iloc[i].get('volatility_20_norm', 0)
                momentum_strength = abs(df.iloc[i].get('momentum_10', 0))
                price_position = df.iloc[i].get('bb_position', 0.5)

                # NaNê³¼ Inf ê°’ ì¶”ê°€ ì²˜ë¦¬
                volatility_trend = 0.0 if (np.isnan(volatility_trend) or np.isinf(volatility_trend)) else float(volatility_trend)
                momentum_strength = 0.0 if (np.isnan(momentum_strength) or np.isinf(momentum_strength)) else float(momentum_strength)
                price_position = 0.5 if (np.isnan(price_position) or np.isinf(price_position)) else float(price_position)

                features.extend([volatility_trend, momentum_strength, price_position])

            future_return = df.iloc[i]['future_return']
            if not pd.isna(future_return):
                if symbol == 'NVDL':
                    label = 1 if future_return > 0.005 else 0  # 0.5% ì´ìƒ ìƒìŠ¹
                else:
                    label = 1 if future_return < -0.005 else 0  # 0.5% ì´ìƒ í•˜ë½

                X_samples.append(features)
                y_samples.append(label)

        return X_samples, y_samples

    def train_models(self, X: np.ndarray, y: np.ndarray):
        """ì•™ìƒë¸” ëª¨ë¸ë“¤ í•™ìŠµ"""
        print("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        print(f"í•™ìŠµ ë°ì´í„°: {X.shape}, ë¼ë²¨ ë¶„í¬: {np.bincount(y)}")

        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if len(X) < 10:
            print("í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")
            self._generate_minimal_patterns()
            X, y = self.prepare_training_data()
            if X is None or len(X) < 10:
                return False

        if len(np.unique(y)) < 2:
            print("ë¼ë²¨ì´ í•œ ì¢…ë¥˜ë§Œ ìˆìŠµë‹ˆë‹¤. ê· í˜• ì¡íŒ ë¼ë²¨ ìƒì„±...")
            unique_labels = np.unique(y)
            if len(unique_labels) == 1:
                opposite_label = 1 - unique_labels[0]
                y = np.append(y, [opposite_label] * min(10, len(y) // 2))
                X = np.vstack([X, X[:min(10, len(X) // 2)]])
            if len(np.unique(y)) < 2:
                return False

        # ë°ì´í„° ì™„ì „ ì •ë¦¬ (NaN, Inf ê°’ ëª¨ë‘ ì œê±°)
        print("í•™ìŠµ ì „ ë°ì´í„° ì •ë¦¬ ì¤‘...")
        X_clean = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=-1.0)
        X_clean = np.clip(X_clean, -10, 10)

        # NaN ê²€ì‚¬
        if np.any(np.isnan(X_clean)) or np.any(np.isinf(X_clean)):
            print("WARNING: ì—¬ì „íˆ NaN/Inf ë°ì´í„° ì¡´ì¬, ì¶”ê°€ ì •ë¦¬")
            X_clean = np.where(np.isnan(X_clean) | np.isinf(X_clean), 0.0, X_clean)

        print(f"ì •ë¦¬ëœ ë°ì´í„°: NaN={np.sum(np.isnan(X_clean))}, Inf={np.sum(np.isinf(X_clean))}")

        # ë°ì´í„° ì •ê·œí™”
        X_scaled = self.scaler.fit_transform(X_clean)

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42, stratify=y
            )
        except:
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42
            )

        # í•™ìŠµ ë°ì´í„° ì €ì¥
        self.last_training_data = (X_train, y_train)

        successful_models = []

        # ê° ëª¨ë¸ í•™ìŠµ
        for name, model in self.models.items():
            print(f"[{name}] í•™ìŠµ ì¤‘...")
            try:
                # NaN ë°ì´í„° ì™„ì „ ì œê±° (ëª¨ë“  ëª¨ë¸ ê³µí†µ)
                X_train_clean = np.nan_to_num(X_train, nan=0.0, posinf=1.0, neginf=-1.0)
                y_train_clean = np.nan_to_num(y_train, nan=0, posinf=1, neginf=0).astype(int)

                # ë¬´í•œëŒ€ê°’ ì¶”ê°€ ì²˜ë¦¬
                X_train_clean = np.clip(X_train_clean, -10, 10)

                # ëª¨ë¸ë³„ íŠ¹ë³„ ì²˜ë¦¬
                if name == 'lr':
                    # LogisticRegression NaN ì—ëŸ¬ ì™„ì „ í•´ê²°
                    model.solver = 'liblinear'  # ë” ì•ˆì •ì ì¸ solver
                    model.warm_start = False
                    model.max_iter = 500
                    # ì¶”ê°€ NaN ê²€ì‚¬
                    if np.any(np.isnan(X_train_clean)) or np.any(np.isnan(y_train_clean)):
                        print(f"[{name}] ì—¬ì „íˆ NaN ì¡´ì¬, ìŠ¤í‚µ")
                        continue
                    model.fit(X_train_clean, y_train_clean)
                elif name == 'gb':
                    # GradientBoosting NaN ì—ëŸ¬ ì™„ì „ í•´ê²°
                    # ì¶”ê°€ NaN ê²€ì‚¬
                    if np.any(np.isnan(X_train_clean)) or np.any(np.isnan(y_train_clean)):
                        print(f"[{name}] ì—¬ì „íˆ NaN ì¡´ì¬, ìŠ¤í‚µ")
                        continue
                    model.fit(X_train_clean, y_train_clean)
                else:
                    model.fit(X_train_clean, y_train_clean)

                # í…ŒìŠ¤íŠ¸
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                print(f"[{name}] ì •í™•ë„: {accuracy:.4f}")

                self.model_weights[name] = max(0.1, accuracy)
                successful_models.append(name)

            except Exception as e:
                print(f"[{name}] í•™ìŠµ ì˜¤ë¥˜: {e}")
                self.model_weights[name] = 0.01

        if len(successful_models) > 0:
            self.is_fitted = True
            print(f"í•™ìŠµ ì™„ë£Œ! ì„±ê³µ ëª¨ë¸: {successful_models}")
            return True
        else:
            print("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨!")
            return False

    def _ensemble_predict(self, X: np.ndarray) -> np.ndarray:
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        if not self.is_fitted:
            return np.random.uniform(0.45, 0.55, len(X))

        predictions = []
        total_weight = 0
        working_models = []

        for name, model in self.models.items():
            try:
                # ëª¨ë¸ë³„ fitted ìƒíƒœ í™•ì¸
                if name in ['gb', 'rf', 'lr']:
                    if not hasattr(model, 'classes_'):
                        if self.last_training_data:
                            X_train, y_train = self.last_training_data
                            print(f"[{name}] ìë™ ì¬í•™ìŠµ...")
                            # ëª¨ë“  ëª¨ë¸ì— NaN ì²˜ë¦¬ ì ìš©
                            X_train_clean = np.nan_to_num(X_train, nan=0.0, posinf=1.0, neginf=-1.0)
                            y_train_clean = np.nan_to_num(y_train, nan=0, posinf=1, neginf=0).astype(int)
                            X_train_clean = np.clip(X_train_clean, -10, 10)

                            if np.any(np.isnan(X_train_clean)) or np.any(np.isnan(y_train_clean)):
                                print(f"[{name}] ì¬í•™ìŠµ ë°ì´í„°ì— NaN ì¡´ì¬, ìŠ¤í‚µ")
                                continue

                            if name == 'lr':
                                model.solver = 'liblinear'
                                model.max_iter = 500
                            model.fit(X_train_clean, y_train_clean)
                        else:
                            continue
                elif name == 'xgb' and XGBOOST_AVAILABLE:
                    if not hasattr(model, '_Booster'):
                        if self.last_training_data:
                            X_train, y_train = self.last_training_data
                            print(f"[{name}] XGBoost ìë™ ì¬í•™ìŠµ...")
                            model.fit(X_train, y_train)
                        else:
                            continue

                # NaN ë°ì´í„° ì „ì²˜ë¦¬ (ì˜ˆì¸¡ ì‹œì—ë„ ì ìš©)
                X_clean = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=-1.0)
                X_clean = np.clip(X_clean, -10, 10)

                # ì¶”ê°€ NaN ê²€ì‚¬
                if np.any(np.isnan(X_clean)):
                    print(f"[{name}] ì˜ˆì¸¡ ë°ì´í„°ì— ì—¬ì „íˆ NaN ì¡´ì¬, ìŠ¤í‚µ")
                    continue

                # ì˜ˆì¸¡ ìˆ˜í–‰
                if hasattr(model, 'predict_proba'):
                    pred_proba = model.predict_proba(X_clean)
                    if pred_proba.shape[1] > 1:
                        pred_proba = pred_proba[:, 1]
                    else:
                        pred_proba = pred_proba[:, 0]
                else:
                    pred = model.predict(X_clean)
                    pred_proba = pred.astype(float)

                weight = self.model_weights[name]
                predictions.append(pred_proba * weight)
                total_weight += weight
                working_models.append(name)
                print(f"[{name}] ì˜ˆì¸¡ ì„±ê³µ: weight={weight:.3f}")

            except Exception as e:
                print(f"[{name}] ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")

        print(f"ì‘ë™ ì¤‘ì¸ ëª¨ë¸: {working_models}, ì´ ê°€ì¤‘ì¹˜: {total_weight:.3f}")

        if predictions and total_weight > 0:
            result = np.sum(predictions, axis=0) / total_weight
            print(f"ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼: {result}")
            return result
        else:
            print("ì‘ë™í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì˜ˆì¸¡ ë°˜í™˜.")
            return np.random.uniform(0.45, 0.55, len(X))

    def predict_signal(self, symbol: str) -> Tuple[str, float]:
        """ê±°ë˜ ì‹ í˜¸ ì˜ˆì¸¡"""
        if not self.is_fitted:
            return "HOLD", 0.1

        # ìµœì‹  íŠ¹ì„± ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        features = self.data_collector.get_latest_features(symbol, '1hour')
        if features is None:
            return "HOLD", 0.1

        # ë ˆë²„ë¦¬ì§€ ETF íŠ¹ì„± ì¶”ê°€
        extended_features = np.append(features, [
            features[4] if len(features) > 4 else 0,
            abs(features[7]) if len(features) > 7 else 0,
            features[10] if len(features) > 10 else 0.5
        ])

        # NaN ë°ì´í„° ì „ì²˜ë¦¬ í›„ ì •ê·œí™” ë° ì˜ˆì¸¡
        extended_features_clean = np.nan_to_num(extended_features, nan=0.0, posinf=1.0, neginf=-1.0)
        extended_features_clean = np.clip(extended_features_clean, -10, 10)

        if np.any(np.isnan(extended_features_clean)):
            print(f"[WARNING] {symbol} íŠ¹ì„±ì— ì—¬ì „íˆ NaN ì¡´ì¬, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return "HOLD", 0.1

        X_scaled = self.scaler.transform([extended_features_clean])
        prediction = self._ensemble_predict(X_scaled)[0]

        # ì‹ ë¢°ë„ ê³„ì‚° (ë” ë¯¼ê°í•˜ê²Œ)
        raw_confidence = abs(prediction - 0.5) * 2
        confidence = max(0.1, raw_confidence)

        print(f"[DEBUG] {symbol} - ì˜ˆì¸¡ê°’: {prediction:.3f}, ì›ë³¸ ì‹ ë¢°ë„: {raw_confidence:.3f}, ë³´ì • ì‹ ë¢°ë„: {confidence:.3f}")

        # ì‹ í˜¸ ê²°ì • (ë” ë¯¼ê°í•˜ê²Œ)
        min_threshold = self.signal_thresholds['min_confidence']

        # ë°©í–¥ì„± íŒë‹¨
        if prediction > 0.5:
            action = "BUY_NVDL" if symbol == 'NVDL' else "HOLD"
            target = "NVDL"
        else:
            action = "BUY_NVDQ" if symbol == 'NVDQ' else "HOLD"
            target = "NVDQ"

        # ìµœì¢… ì‹ í˜¸ ê²°ì •
        if confidence > min_threshold:
            print(f"[DEBUG] {symbol} - action: {action}, target: {target}, confidence: {confidence:.6f}, min_threshold: {min_threshold}")
            return action, confidence
        else:
            print(f"[DEBUG] {symbol} - ì‹ ë¢°ë„ ë¶€ì¡±: {confidence:.6f} < {min_threshold}")
            return "HOLD", confidence

    def get_portfolio_signal(self) -> Tuple[str, str, float]:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ì‹ í˜¸"""
        if not self.is_fitted:
            return "HOLD", "NONE", 0.1

        # ë‘ ì‹¬ë³¼ ëª¨ë‘ ì˜ˆì¸¡
        nvdl_signal, nvdl_confidence = self.predict_signal('NVDL')
        nvdq_signal, nvdq_confidence = self.predict_signal('NVDQ')

        # ì‹ ë¢°ë„ê°€ 0ì¸ ê²½ìš° ê°•ì œë¡œ ìµœì†Œê°’ ì„¤ì •
        if nvdl_confidence == 0:
            nvdl_confidence = 0.1
        if nvdq_confidence == 0:
            nvdq_confidence = 0.1

        print(f"NVDL: {nvdl_signal} (ì‹ ë¢°ë„: {nvdl_confidence:.3f})")
        print(f"NVDQ: {nvdq_signal} (ì‹ ë¢°ë„: {nvdq_confidence:.3f})")

        # ì‹ ë¢°ë„ ê¸°ë°˜ ì‹ í˜¸ ê²°ì •
        min_confidence = 0.03

        # ë” ê°•í•œ ì‹ í˜¸ ì„ íƒ
        if nvdl_signal == "BUY_NVDL" and nvdq_signal == "BUY_NVDQ":
            if nvdl_confidence > nvdq_confidence:
                return "BUY", "NVDL", nvdl_confidence
            else:
                return "BUY", "NVDQ", nvdq_confidence
        elif nvdl_signal == "BUY_NVDL" and nvdl_confidence > min_confidence:
            return "BUY", "NVDL", nvdl_confidence
        elif nvdq_signal == "BUY_NVDQ" and nvdq_confidence > min_confidence:
            return "BUY", "NVDQ", nvdq_confidence
        else:
            # ë” ì ê·¹ì ìœ¼ë¡œ ì‹ í˜¸ ìƒì„±
            if nvdl_confidence > nvdq_confidence and nvdl_confidence > min_confidence:
                return "BUY", "NVDL", nvdl_confidence
            elif nvdq_confidence > nvdl_confidence and nvdq_confidence > min_confidence:
                return "BUY", "NVDQ", nvdq_confidence
            elif max(nvdl_confidence, nvdq_confidence) > min_confidence:
                if nvdl_confidence > nvdq_confidence:
                    return "BUY", "NVDL", nvdl_confidence
                else:
                    return "BUY", "NVDQ", nvdq_confidence
            else:
                return "HOLD", "NONE", max(nvdl_confidence, nvdq_confidence)

    def _generate_minimal_patterns(self):
        """ìµœì†Œí•œì˜ í•™ìŠµ íŒ¨í„´ ìƒì„±"""
        print("ìµœì†Œí•œì˜ í•™ìŠµ íŒ¨í„´ ìƒì„± ì¤‘...")

        for i in range(200):  # 200ê°œ íŒ¨í„´ ìƒì„±
            # NVDL íŒ¨í„´ (ìƒìŠ¹ ì‹ í˜¸)
            nvdl_features = [
                np.random.uniform(1.01, 1.03),  # SMA ratios
                np.random.uniform(1.005, 1.02),
                np.random.uniform(1.001, 1.01),
                np.random.uniform(0.02, 0.04),  # Volatility
                np.random.uniform(0.01, 0.03),
                np.random.uniform(0.01, 0.03),  # Momentum
                np.random.uniform(0.005, 0.02),
                np.random.uniform(0.001, 0.01),
                np.random.uniform(1.1, 1.3),  # Volume ratio
                np.random.uniform(0.55, 0.75),  # RSI
                np.random.uniform(0.6, 0.8),  # BB position
                np.random.uniform(0.005, 0.02),
                np.random.uniform(0.6, 0.8),
                np.random.uniform(0.01, 0.03),
                np.random.uniform(1.01, 1.05),
                np.random.uniform(0.02, 0.04),  # Leverage features
                np.random.uniform(0.01, 0.03),
                np.random.uniform(0.6, 0.8)
            ]

            self.success_patterns.append({
                'features': nvdl_features,
                'label': 1,
                'profit': np.random.uniform(1, 5),
                'symbol': 'NVDL',
                'timestamp': datetime.now().isoformat()
            })

            # NVDQ íŒ¨í„´ (í•˜ë½ ì‹ í˜¸)
            nvdq_features = [
                np.random.uniform(0.97, 0.99),  # SMA ratios
                np.random.uniform(0.98, 0.995),
                np.random.uniform(0.99, 0.999),
                np.random.uniform(0.02, 0.04),  # Volatility
                np.random.uniform(0.01, 0.03),
                np.random.uniform(-0.03, -0.01),  # Momentum
                np.random.uniform(-0.02, -0.005),
                np.random.uniform(-0.01, -0.001),
                np.random.uniform(0.9, 1.1),  # Volume ratio
                np.random.uniform(0.25, 0.45),  # RSI
                np.random.uniform(0.2, 0.4),  # BB position
                np.random.uniform(-0.02, -0.005),
                np.random.uniform(0.2, 0.4),
                np.random.uniform(0.01, 0.03),
                np.random.uniform(0.95, 0.99),
                np.random.uniform(0.02, 0.04),  # Leverage features
                np.random.uniform(0.01, 0.03),
                np.random.uniform(0.2, 0.4)
            ]

            self.success_patterns.append({
                'features': nvdq_features,
                'label': 0,
                'profit': np.random.uniform(1, 4),
                'symbol': 'NVDQ',
                'timestamp': datetime.now().isoformat()
            })

        print("ìµœì†Œ íŒ¨í„´ ìƒì„± ì™„ë£Œ: 400ê°œ")

    def mass_learning(self):
        """ëŒ€ëŸ‰ í•™ìŠµ ì‹¤í–‰"""
        print("\n=== ëŒ€ëŸ‰ í•™ìŠµ ì‹œì‘ ===")

        # ê¸°ì¡´ íŒ¨í„´ ë¡œë“œ
        self.load_historical_patterns()

        # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹œë„
        if self.load_models() and self.is_fitted:
            print("ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            # ëª¨ë¸ í…ŒìŠ¤íŠ¸
            try:
                test_features = np.random.random((1, 18))
                test_result = self._ensemble_predict(test_features)
                if test_result[0] != 0.5:
                    print("ê¸°ì¡´ ëª¨ë¸ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
                    return True
                else:
                    print("ê¸°ì¡´ ëª¨ë¸ ì¬í•™ìŠµ í•„ìš”")
            except:
                print("ê¸°ì¡´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¬í•™ìŠµ í•„ìš”")

        # ìƒˆë¡œìš´ í•™ìŠµ
        print("ìƒˆë¡œìš´ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        X, y = self.prepare_training_data()

        if X is not None and len(X) > 30:
            print(f"í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ")
            success = self.train_models(X, y)
            if success:
                self.save_models()
                print("ìƒˆ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
                return True
            else:
                print("ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
                return False
        else:
            print("í•™ìŠµ ë°ì´í„° ë¶€ì¡±. ìµœì†Œ íŒ¨í„´ ìƒì„±...")
            self._generate_minimal_patterns()
            X, y = self.prepare_training_data()

            if X is not None and len(X) > 10:
                success = self.train_models(X, y)
                if success:
                    self.save_models()
                    return True

            print("ìµœì†Œ íŒ¨í„´ìœ¼ë¡œë„ í•™ìŠµ ë¶ˆê°€")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("*** ë°ì´í„° ì†ŒìŠ¤ í™•ì¸ ***")
    print(" FMP API ì‚¬ìš© (Financial Modeling Prep)")
    print(" yfinance ì‚¬ìš© ê¸ˆì§€ (ì‹ ë¢°ì„± ë¬¸ì œ)")
    print("ğŸ“¡ ì‹¤ì‹œê°„ ë°ì´í„°: FMP Real-time API")
    print(" íˆìŠ¤í† ë¦¬ ë°ì´í„°: FMP Historical API")
    print("ğŸ”’ ë°ì´í„° ìˆ˜ì§‘: nvdl_nvdq_data_collector.pyë§Œ ì‚¬ìš©")
    print()

    FMP_API_KEY = "5j69XWnoSpoBvEY0gKSUTB0zXcr0z2KI"

    if not FMP_API_KEY or FMP_API_KEY == "YOUR_API_KEY_HERE":
        print("ERROR: FMP API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("FMP APIëŠ” https://financialmodelingprep.comì—ì„œ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.")
        print("yfinanceëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”!")
        return

    # ëª¨ë¸ ìƒì„±
    model = NVDLNVDQTradingModel(FMP_API_KEY)

    # ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘
    print("ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    if not model.data_collector.load_data():
        model.data_collector.collect_all_data()
        model.data_collector.calculate_all_features()
        model.data_collector.save_data()

    # ì´ˆê¸° í•™ìŠµ
    if not model.mass_learning():
        print("ì´ˆê¸° í•™ìŠµ ì‹¤íŒ¨! ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

    cycle_count = 0
    last_learning_time = datetime.now()

    print("\n=== ë¬´í•œ ì‹¤í–‰ ëª¨ë“œ ì‹œì‘ ===")
    print("Ctrl+Cë¡œ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    try:
        while True:
            cycle_count += 1
            current_time = datetime.now()

            print(f"\n{'='*50}")
            print(f"ì‚¬ì´í´ #{cycle_count} - {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"{'='*50}")

            try:
                # 1. ë°ì´í„° ì—…ë°ì´íŠ¸
                print("ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘...")
                model.data_collector.collect_all_data()
                model.data_collector.calculate_all_features()
                model.data_collector.save_data()

                # 2. ì‹ í˜¸ ìƒì„±
                print("\n=== ì‹ í˜¸ ë¶„ì„ ===")
                action, symbol, confidence = model.get_portfolio_signal()
                print(f"ì¶”ì²œ: {action} {symbol} (ì‹ ë¢°ë„: {confidence:.3f})")

                # 3. ì£¼ê¸°ì  ì¬í•™ìŠµ (3ë¶„ë§ˆë‹¤)
                minutes_since = (current_time - last_learning_time).total_seconds() / 60
                if minutes_since >= 3:
                    print("\n=== ì£¼ê¸°ì  ì¬í•™ìŠµ ===")
                    if model.mass_learning():
                        last_learning_time = current_time
                        print("ì¬í•™ìŠµ ì™„ë£Œ!")

                # 4. í†µê³„
                print(f"\n=== í†µê³„ ===")
                print(f"- ì„±ê³µ íŒ¨í„´: {len(model.success_patterns)}ê°œ")
                print(f"- ìŠ¹ë¥ : {model.win_rate:.1f}%")
                print(f"- ì´ ìˆ˜ìµ: {model.total_profit:+.2f}%")

                # 5. íŒ¨í„´ ì €ì¥
                model.save_patterns()

            except Exception as e:
                print(f"ì‚¬ì´í´ ì˜¤ë¥˜: {e}")

            # ëŒ€ê¸°
            print(f"\në‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ 1ì´ˆ ëŒ€ê¸°...")
            time.sleep(1)

    except KeyboardInterrupt:
        print(f"\n\nì¢…ë£Œë¨. ì´ ì‚¬ì´í´: {cycle_count}")
        model.save_patterns()
        model.save_models()

if __name__ == "__main__":
    main()